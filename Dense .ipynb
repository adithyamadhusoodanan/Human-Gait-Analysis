{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gait = pd.read_csv(\"gaitFull.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gait.drop('label',  axis=1)\n",
    "y = gait['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train=list(moving_window(y_train, 1))\n",
    "y_train=np.asarray(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "test=y_test\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train(data_array):\n",
    "    seq_length=10\n",
    "    num_elements = data_array.shape[0]\n",
    "    lstm_array=[]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "            lstm_array.append(data_array[start:stop, :])\n",
    "    return np.array(lstm_array)\n",
    "X_train=gen_train(X_train)\n",
    "X_test=gen_train(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1890, 10, 11)\n",
      "(466, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape((1890,11,10))\n",
    "X_test=X_test.reshape((466,11,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_label(data_array):    \n",
    "    seq_length=10\n",
    "    num_elements = data_array.shape[0]\n",
    "    y_label=[]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        y_label.append(data_array[stop])\n",
    "    return np.array(y_label)\n",
    "y_train=gen_label(y_train)\n",
    "y_test=gen_label(y_test)\n",
    "test=gen_label(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout , BatchNormalization, LSTM,Conv1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 64)                19200     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 196)               25284     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                6304      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 67,948\n",
      "Trainable params: 67,820\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "model.add(LSTM(64,activation='relu',input_shape=(n_timesteps, n_features)))\n",
    "model.add(Dense(64, input_dim=X_train.shape[1] , activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(196, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.0005),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adithya/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "filepath=\"HAR_weights.hdf5\"\n",
    "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1890 samples, validate on 466 samples\n",
      "Epoch 1/30\n",
      "1890/1890 [==============================] - 1s 463us/step - loss: 2.0841 - accuracy: 0.1317 - val_loss: 2.1296 - val_accuracy: 0.1459\n",
      "Epoch 2/30\n",
      "1890/1890 [==============================] - 0s 70us/step - loss: 2.0619 - accuracy: 0.1704 - val_loss: 2.1421 - val_accuracy: 0.1567\n",
      "Epoch 3/30\n",
      " 256/1890 [===>..........................] - ETA: 0s - loss: 2.0533 - accuracy: 0.1367"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adithya/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "/Users/adithya/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1890/1890 [==============================] - 0s 71us/step - loss: 2.0517 - accuracy: 0.1630 - val_loss: 2.1456 - val_accuracy: 0.1524\n",
      "Epoch 4/30\n",
      "1890/1890 [==============================] - 0s 70us/step - loss: 2.0438 - accuracy: 0.1720 - val_loss: 2.1443 - val_accuracy: 0.1373\n",
      "Epoch 5/30\n",
      "1890/1890 [==============================] - 0s 71us/step - loss: 2.0334 - accuracy: 0.1762 - val_loss: 2.1430 - val_accuracy: 0.1330\n",
      "Epoch 6/30\n",
      "1890/1890 [==============================] - 0s 68us/step - loss: 2.0243 - accuracy: 0.1857 - val_loss: 2.1310 - val_accuracy: 0.1202\n",
      "Epoch 7/30\n",
      "1890/1890 [==============================] - 0s 68us/step - loss: 2.0171 - accuracy: 0.1926 - val_loss: 2.1459 - val_accuracy: 0.1245\n",
      "Epoch 8/30\n",
      "1890/1890 [==============================] - 0s 70us/step - loss: 2.0047 - accuracy: 0.1984 - val_loss: 2.1432 - val_accuracy: 0.1180\n",
      "Epoch 9/30\n",
      "1890/1890 [==============================] - 0s 69us/step - loss: 1.9926 - accuracy: 0.2026 - val_loss: 2.1471 - val_accuracy: 0.1245\n",
      "Epoch 10/30\n",
      "1890/1890 [==============================] - 0s 68us/step - loss: 1.9794 - accuracy: 0.2079 - val_loss: 2.1465 - val_accuracy: 0.1266\n",
      "Epoch 11/30\n",
      "1890/1890 [==============================] - 0s 71us/step - loss: 1.9651 - accuracy: 0.2265 - val_loss: 2.1638 - val_accuracy: 0.1330\n",
      "Epoch 12/30\n",
      "1890/1890 [==============================] - 0s 73us/step - loss: 1.9499 - accuracy: 0.2376 - val_loss: 2.1598 - val_accuracy: 0.1309\n",
      "Epoch 13/30\n",
      "1890/1890 [==============================] - 0s 71us/step - loss: 1.9346 - accuracy: 0.2381 - val_loss: 2.1650 - val_accuracy: 0.1352\n",
      "Epoch 14/30\n",
      "1890/1890 [==============================] - 0s 67us/step - loss: 1.9108 - accuracy: 0.2683 - val_loss: 2.1795 - val_accuracy: 0.1288\n",
      "Epoch 15/30\n",
      "1890/1890 [==============================] - 0s 73us/step - loss: 1.8850 - accuracy: 0.2810 - val_loss: 2.2042 - val_accuracy: 0.1309\n",
      "Epoch 16/30\n",
      "1890/1890 [==============================] - 0s 72us/step - loss: 1.8704 - accuracy: 0.2873 - val_loss: 2.2106 - val_accuracy: 0.1202\n",
      "Epoch 17/30\n",
      "1890/1890 [==============================] - 0s 69us/step - loss: 1.8334 - accuracy: 0.3048 - val_loss: 2.2330 - val_accuracy: 0.1309\n",
      "Epoch 18/30\n",
      "1890/1890 [==============================] - 0s 66us/step - loss: 1.8205 - accuracy: 0.3021 - val_loss: 2.2167 - val_accuracy: 0.1223\n",
      "Epoch 19/30\n",
      "1890/1890 [==============================] - 0s 69us/step - loss: 1.7943 - accuracy: 0.3190 - val_loss: 2.2905 - val_accuracy: 0.1180\n",
      "Epoch 20/30\n",
      "1890/1890 [==============================] - 0s 70us/step - loss: 1.7490 - accuracy: 0.3434 - val_loss: 2.3064 - val_accuracy: 0.1159\n",
      "Epoch 21/30\n",
      "1890/1890 [==============================] - 0s 69us/step - loss: 1.7288 - accuracy: 0.3481 - val_loss: 2.3128 - val_accuracy: 0.1416\n",
      "Epoch 22/30\n",
      "1890/1890 [==============================] - 0s 73us/step - loss: 1.6939 - accuracy: 0.3651 - val_loss: 2.3169 - val_accuracy: 0.1137\n",
      "Epoch 23/30\n",
      "1890/1890 [==============================] - 0s 70us/step - loss: 1.6450 - accuracy: 0.3963 - val_loss: 2.3243 - val_accuracy: 0.1266\n",
      "Epoch 24/30\n",
      "1890/1890 [==============================] - 0s 69us/step - loss: 1.6133 - accuracy: 0.4037 - val_loss: 2.3735 - val_accuracy: 0.1180\n",
      "Epoch 25/30\n",
      "1890/1890 [==============================] - 0s 69us/step - loss: 1.5742 - accuracy: 0.4122 - val_loss: 2.3646 - val_accuracy: 0.1202\n",
      "Epoch 26/30\n",
      "1890/1890 [==============================] - 0s 68us/step - loss: 1.5459 - accuracy: 0.4407 - val_loss: 2.4345 - val_accuracy: 0.1288\n",
      "Epoch 27/30\n",
      "1890/1890 [==============================] - 0s 71us/step - loss: 1.5203 - accuracy: 0.4402 - val_loss: 2.4720 - val_accuracy: 0.1180\n",
      "Epoch 28/30\n",
      "1890/1890 [==============================] - 0s 71us/step - loss: 1.4822 - accuracy: 0.4667 - val_loss: 2.4921 - val_accuracy: 0.1223\n",
      "Epoch 29/30\n",
      "1890/1890 [==============================] - 0s 74us/step - loss: 1.4435 - accuracy: 0.4889 - val_loss: 2.5280 - val_accuracy: 0.1202\n",
      "Epoch 30/30\n",
      "1890/1890 [==============================] - 0s 68us/step - loss: 1.4049 - accuracy: 0.4931 - val_loss: 2.5694 - val_accuracy: 0.1202\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train , epochs=30 , batch_size = 256 , validation_data=(X_test, y_test) , callbacks=[checkpoint,lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import rcParams\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis = 1) \n",
    "y_true = np.argmax(y_test,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  3,  2,  0,  0,  0,  0,  0],\n",
       "       [38,  1,  0,  0,  0,  0,  1,  0],\n",
       "       [47,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [43,  1,  1,  0,  0,  0,  3,  0],\n",
       "       [47,  1,  2,  0,  0,  0,  2,  0],\n",
       "       [39,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [56,  1,  1,  0,  0,  0,  2,  0],\n",
       "       [41,  0,  1,  0,  0,  0,  2,  0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.89      0.20        45\n",
      "           1       0.14      0.03      0.04        40\n",
      "           2       0.00      0.00      0.00        48\n",
      "           3       0.00      0.00      0.00        48\n",
      "           4       0.00      0.00      0.00        52\n",
      "           5       0.00      0.00      0.00        39\n",
      "           6       0.18      0.03      0.06        60\n",
      "           7       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.11       376\n",
      "   macro avg       0.05      0.12      0.04       376\n",
      "weighted avg       0.06      0.11      0.04       376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adithya/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report , accuracy_score\n",
    "print(classification_report(y_true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 100, 100)          44800     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                3264      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 196)               25284     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                6304      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 8)                 72        \n",
      "=================================================================\n",
      "Total params: 118,764\n",
      "Trainable params: 118,636\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "model.add(LSTM(\n",
    "         input_shape=(n_timesteps, n_features),\n",
    "         units=100,\n",
    "         return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(\n",
    "         input_shape=(n_timesteps, n_features),\n",
    "         units=50,\n",
    "         return_sequences=False))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(196, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.add(Dense(units=8, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1805 samples, validate on 95 samples\n",
      "Epoch 1/35\n",
      "1805/1805 [==============================] - 0s 232us/step - loss: 2.0105 - accuracy: 0.2366 - val_loss: 3.6136 - val_accuracy: 0.0947\n",
      "Epoch 2/35\n",
      "1805/1805 [==============================] - 0s 19us/step - loss: 1.9234 - accuracy: 0.2975 - val_loss: 3.6884 - val_accuracy: 0.0947\n",
      "Epoch 3/35\n",
      "1805/1805 [==============================] - 0s 15us/step - loss: 1.8578 - accuracy: 0.2510 - val_loss: 3.4021 - val_accuracy: 0.0947\n",
      "Epoch 4/35\n",
      "1805/1805 [==============================] - 0s 17us/step - loss: 1.8127 - accuracy: 0.2626 - val_loss: 3.0284 - val_accuracy: 0.0947\n",
      "Epoch 5/35\n",
      "1805/1805 [==============================] - 0s 15us/step - loss: 1.7802 - accuracy: 0.2864 - val_loss: 2.6221 - val_accuracy: 0.0947\n",
      "Epoch 6/35\n",
      "1805/1805 [==============================] - 0s 14us/step - loss: 1.7730 - accuracy: 0.3030 - val_loss: 2.2872 - val_accuracy: 0.1158\n",
      "Epoch 7/35\n",
      "1805/1805 [==============================] - 0s 13us/step - loss: 1.7630 - accuracy: 0.3191 - val_loss: 2.0818 - val_accuracy: 0.1368\n",
      "Epoch 8/35\n",
      "1805/1805 [==============================] - 0s 14us/step - loss: 1.7403 - accuracy: 0.3690 - val_loss: 1.9492 - val_accuracy: 0.1895\n",
      "Epoch 9/35\n",
      "1805/1805 [==============================] - 0s 14us/step - loss: 1.7349 - accuracy: 0.3723 - val_loss: 1.8563 - val_accuracy: 0.3158\n",
      "Epoch 10/35\n",
      "1805/1805 [==============================] - 0s 14us/step - loss: 1.7097 - accuracy: 0.3634 - val_loss: 1.8510 - val_accuracy: 0.3684\n",
      "Epoch 11/35\n",
      "1805/1805 [==============================] - 0s 13us/step - loss: 1.6938 - accuracy: 0.3729 - val_loss: 1.8090 - val_accuracy: 0.4000\n",
      "Epoch 12/35\n",
      "1805/1805 [==============================] - 0s 13us/step - loss: 1.6692 - accuracy: 0.3839 - val_loss: 1.7909 - val_accuracy: 0.3263\n",
      "Epoch 13/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.6598 - accuracy: 0.4144 - val_loss: 1.7515 - val_accuracy: 0.3158\n",
      "Epoch 14/35\n",
      "1805/1805 [==============================] - 0s 13us/step - loss: 1.6319 - accuracy: 0.4277 - val_loss: 1.7552 - val_accuracy: 0.2842\n",
      "Epoch 15/35\n",
      "1805/1805 [==============================] - 0s 13us/step - loss: 1.6114 - accuracy: 0.4072 - val_loss: 1.7443 - val_accuracy: 0.3579\n",
      "Epoch 16/35\n",
      "1805/1805 [==============================] - 0s 13us/step - loss: 1.6195 - accuracy: 0.4166 - val_loss: 1.7201 - val_accuracy: 0.3263\n",
      "Epoch 17/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.6187 - accuracy: 0.4199 - val_loss: 1.7818 - val_accuracy: 0.2947\n",
      "Epoch 18/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.6086 - accuracy: 0.4316 - val_loss: 1.7446 - val_accuracy: 0.3053\n",
      "Epoch 19/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.5877 - accuracy: 0.4504 - val_loss: 1.8095 - val_accuracy: 0.2737\n",
      "Epoch 20/35\n",
      "1805/1805 [==============================] - 0s 13us/step - loss: 1.5784 - accuracy: 0.4349 - val_loss: 1.7821 - val_accuracy: 0.3368\n",
      "Epoch 21/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.5647 - accuracy: 0.4521 - val_loss: 1.6566 - val_accuracy: 0.4526\n",
      "Epoch 22/35\n",
      "1805/1805 [==============================] - 0s 13us/step - loss: 1.5588 - accuracy: 0.4510 - val_loss: 1.8055 - val_accuracy: 0.2947\n",
      "Epoch 23/35\n",
      "1805/1805 [==============================] - 0s 13us/step - loss: 1.5801 - accuracy: 0.4255 - val_loss: 1.8673 - val_accuracy: 0.2105\n",
      "Epoch 24/35\n",
      "1805/1805 [==============================] - 0s 13us/step - loss: 1.5270 - accuracy: 0.4620 - val_loss: 1.7787 - val_accuracy: 0.2947\n",
      "Epoch 25/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.5332 - accuracy: 0.4421 - val_loss: 1.7217 - val_accuracy: 0.3368\n",
      "Epoch 26/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.5613 - accuracy: 0.4321 - val_loss: 1.7494 - val_accuracy: 0.3789\n",
      "Epoch 27/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.5182 - accuracy: 0.4532 - val_loss: 1.6322 - val_accuracy: 0.3053\n",
      "Epoch 28/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.4934 - accuracy: 0.4753 - val_loss: 1.6596 - val_accuracy: 0.2737\n",
      "Epoch 29/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.4894 - accuracy: 0.4582 - val_loss: 1.6563 - val_accuracy: 0.2947\n",
      "Epoch 30/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.4928 - accuracy: 0.4532 - val_loss: 1.5589 - val_accuracy: 0.3579\n",
      "Epoch 31/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.4842 - accuracy: 0.4554 - val_loss: 1.6561 - val_accuracy: 0.3368\n",
      "Epoch 32/35\n",
      "1805/1805 [==============================] - 0s 13us/step - loss: 1.4617 - accuracy: 0.4582 - val_loss: 1.5528 - val_accuracy: 0.4105\n",
      "Epoch 33/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.4805 - accuracy: 0.4526 - val_loss: 1.6126 - val_accuracy: 0.3579\n",
      "Epoch 34/35\n",
      "1805/1805 [==============================] - 0s 12us/step - loss: 1.4684 - accuracy: 0.4681 - val_loss: 1.5459 - val_accuracy: 0.3789\n",
      "Epoch 35/35\n",
      "1805/1805 [==============================] - 0s 13us/step - loss: 1.4535 - accuracy: 0.4748 - val_loss: 1.6008 - val_accuracy: 0.3053\n"
     ]
    }
   ],
   "source": [
    "# fit the network\n",
    "history=model.fit(X_train, y_train, epochs=35, batch_size=200, validation_split=0.05, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900/1900 [==============================] - 0s 7us/step\n",
      "Accurracy: 0.3484210669994354\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_train, y_train, verbose=1, batch_size=200)\n",
    "print('Accurracy: {}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model on test data:  0.28361344537815125\n",
      "Confusion Matrix: \n",
      " [[39  2  3  0  0  2  3  4]\n",
      " [25 10 12  0  0  1  1  1]\n",
      " [15 12 34  0  0  1  4  0]\n",
      " [22  1 12  0  1  7  6 10]\n",
      " [14  1  5  0  2 43  1  4]\n",
      " [17  2  4  0  0 18  8  2]\n",
      " [13  0 17  0  0  3 28 10]\n",
      " [31  0  9  0  0  4  8  4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred=model.predict_classes(X_test)\n",
    "print('Accuracy of model on test data: ',accuracy_score(test,y_pred))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([45, 40, 48, 48, 52, 39, 60, 44]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
